{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3add79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87122739",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from this import d\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "# THIS WILL BE CALLED WHEN GRID_MODEL IS ACTIVE\n",
    "# this function manages solar and wind generation at the grid cell level\n",
    "# it then aggregates the solar and wind generation to the bus level\n",
    "# it then creates the pre and post tables for the solar and wind generation\n",
    "# it then creates the pre and post tables for the aggregator\n",
    "# it then creates the pre and post tables for the aggregator\n",
    "\n",
    "input_iso = 'CHE'\n",
    "\n",
    "\n",
    "# Simple read - this should come from the cache\n",
    "df_solar_rezoning = pd.read_csv(\"../data/REZoning/REZoning_Solar.csv\")\n",
    "\n",
    "df_solar = df_solar_rezoning[df_solar_rezoning['ISO'] == input_iso]\n",
    "# For each distinct grid_cell, retain the row with the maximum Installed Capacity Potential (MW)\n",
    "# If there are ties, also retain the maximum Capacity Factor for that grid_cell\n",
    "\n",
    "# First, sort by 'Calculated Installed Cap' descending, then by 'Capacity Factor' descending\n",
    "df_solar = df_solar.sort_values(['grid_cell', 'Installed Capacity Potential (MW)', 'Capacity Factor'], ascending=[True, False, False])\n",
    "\n",
    "# Drop duplicates, keeping the row with the highest Installed Cap (and highest Capacity Factor in case of ties)\n",
    "df_solar = df_solar.drop_duplicates(subset=['grid_cell'], keep='first')\n",
    "\n",
    "\n",
    "df_rez_grid_to_bus = pd.read_csv(f\"output/{input_iso}/{input_iso}_zone_bus_mapping.csv\")\n",
    "\n",
    "df_rez_grid_to_bus['bus_id'] = df_rez_grid_to_bus['bus_id'].str.replace('way/', 'w', regex=False).str.replace('relation/', 'r', regex=False)\n",
    "\n",
    "\n",
    "duckdb.register('df_rez_grid_to_bus', df_rez_grid_to_bus)\n",
    "duckdb.register('df_solar', df_solar)\n",
    "\n",
    "df_solar_fi_t = duckdb.sql(f\"\"\"\n",
    "SELECT\n",
    "    grid_cell AS \"grid_cell\",\n",
    "    'e_sol-' || ISO || '_' || LPAD(CAST(id AS VARCHAR), 4, '0') AS \"process\",\n",
    "    'elc_sol-' || ISO || '_' || LPAD(CAST(id AS VARCHAR), 4, '0') AS \"comm-out\",\n",
    "    \"Installed Capacity Potential (MW)\"/1000 AS \"cap_bnd\",\n",
    "    \"Capacity Factor\" AS \"af~fx\",\n",
    "    FROM df_solar\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_solar_fi_t)\n",
    "\n",
    "duckdb.register('df_solar_fi_t', df_solar_fi_t)\n",
    "\n",
    "df_solar_fi_p = duckdb.sql(\"\"\"\n",
    "select \n",
    "'ele' AS set,\n",
    "process,'solar resource in grid cell ' || grid_cell AS description,\n",
    "'GW' AS capacity_unit,\n",
    "'TWh' AS activity_unit,\n",
    "'annual' AS timeslicelevel,\n",
    "'no' AS vintage\n",
    "from df_solar_fi_t T1\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_solar_fi_p)\n",
    "\n",
    "df_agg_sol_fi_t = duckdb.sql(f\"\"\"\n",
    "SELECT\n",
    "    'distr_' || \"comm-out\" AS process,\n",
    "    \"comm-out\" AS \"comm-in\",group_concat('e_' || bus_id) AS \"comm-out\",\n",
    "    1 AS efficiency,\n",
    "    T1.grid_cell,\n",
    "FROM df_solar_fi_t T1\n",
    "INNER JOIN df_rez_grid_to_bus T2\n",
    "ON T1.grid_cell = T2.grid_cell\n",
    "group by \"comm-out\",T1.grid_cell\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_agg_sol_fi_t)\n",
    "\n",
    "duckdb.register('df_agg_sol_fi_t', df_agg_sol_fi_t)\n",
    "\n",
    "df_agg_sol_fi_p = duckdb.sql(\"\"\"\n",
    "select \n",
    "'pre' AS set,\n",
    "process,'connecting solar to buses in grid cell ' || grid_cell AS description,\n",
    "'GW' AS capacity_unit,\n",
    "'TWh' AS activity_unit,\n",
    "\"comm-in\" AS primarycg,\n",
    "'daynite' AS timeslicelevel,\n",
    "'no' AS vintage\n",
    "from df_agg_sol_fi_t T1\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_agg_sol_fi_p)\n",
    "\n",
    "# now do the same for wind\n",
    "# Simple read\n",
    "df_wind = pd.read_csv(\"../data/REZoning/REZoning_WindOnshore.csv\")\n",
    "\n",
    "df_wind = df_wind[df_wind['ISO'] == input_iso]\n",
    "# For each distinct grid_cell, retain the row with the maximum Installed Capacity Potential (MW)\n",
    "# If there are ties, also retain the maximum Capacity Factor for that grid_cell\n",
    "\n",
    "# First, sort by 'Calculated Installed Cap' descending, then by 'Capacity Factor' descending\n",
    "df_wind = df_wind.sort_values(['grid_cell', 'Installed Capacity Potential (MW)', 'Capacity Factor'], ascending=[True, False, False])\n",
    "\n",
    "# Drop duplicates, keeping the row with the highest Installed Cap (and highest Capacity Factor in case of ties)\n",
    "df_wind = df_wind.drop_duplicates(subset=['grid_cell'], keep='first')\n",
    "\n",
    "\n",
    "duckdb.register('df_wind', df_wind)\n",
    "\n",
    "df_wind_fi_t = duckdb.sql(f\"\"\"\n",
    "SELECT\n",
    "    grid_cell AS \"grid_cell\",\n",
    "    'e_win-' || ISO || '_' || LPAD(CAST(id AS VARCHAR), 4, '0') AS \"process\",\n",
    "    'elc_win-' || ISO || '_' || LPAD(CAST(id AS VARCHAR), 4, '0') AS \"comm-out\",\n",
    "    \"Installed Capacity Potential (MW)\"/1000 AS \"cap_bnd\",\n",
    "    \"Capacity Factor\" AS \"af~fx\",\n",
    "    FROM df_wind\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_wind_fi_t)\n",
    "\n",
    "duckdb.register('df_wind_fi_t', df_wind_fi_t)\n",
    "\n",
    "df_wind_fi_p = duckdb.sql(\"\"\"\n",
    "select \n",
    "'ele' AS set,\n",
    "process,'wind resource in grid cell ' || grid_cell AS description,\n",
    "'GW' AS capacity_unit,\n",
    "'TWh' AS activity_unit,\n",
    "'annual' AS timeslicelevel,\n",
    "'no' AS vintage\n",
    "from df_wind_fi_t T1\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_wind_fi_p)\n",
    "\n",
    "df_agg_win_fi_t = duckdb.sql(f\"\"\"\n",
    "SELECT\n",
    "    'distr_' || \"comm-out\" AS process,\n",
    "    \"comm-out\" AS \"comm-in\",group_concat('e_' || bus_id) AS \"comm-out\",\n",
    "    1 AS efficiency,\n",
    "    T1.grid_cell,\n",
    "FROM df_wind_fi_t T1\n",
    "INNER JOIN df_rez_grid_to_bus T2\n",
    "ON T1.grid_cell = T2.grid_cell\n",
    "group by \"comm-out\",T1.grid_cell\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_agg_win_fi_t)\n",
    "\n",
    "duckdb.register('df_agg_win_fi_t', df_agg_win_fi_t)\n",
    "\n",
    "df_agg_win_fi_p = duckdb.sql(\"\"\"\n",
    "select \n",
    "'pre' AS set,\n",
    "process,'connecting wind to buses in grid cell ' || grid_cell AS description,\n",
    "'GW' AS capacity_unit,\n",
    "'TWh' AS activity_unit,\n",
    "\"comm-in\" AS primarycg,\n",
    "'daynite' AS timeslicelevel,\n",
    "'no' AS vintage\n",
    "from df_agg_win_fi_t T1\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_agg_win_fi_p)\n",
    "\n",
    "df_fi_comm_sol_win = duckdb.sql(\"\"\"\n",
    "    select 'NRG' AS \"set\",\"comm-out\" as commodity, 'solar generation in grid cell -- ' || grid_cell as \"description\"\n",
    "        ,'ELC' as commoditytype, 'daynite' as \"timeslicelevel\", 'TWh' as unit\n",
    "        from df_solar_fi_t\n",
    "        UNION\n",
    "        select 'NRG' AS \"set\",\"comm-out\" as commodity, 'wind generation in grid cell -- ' || grid_cell as \"description\"\n",
    "        ,'ELC' as commoditytype, 'daynite' as \"timeslicelevel\", 'TWh' as unit\n",
    "        from df_wind_fi_t\n",
    "        order by \"comm-out\"\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_fi_comm_sol_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dis\n",
    "from this import d\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "def bus_id_to_commodity(bus_id: str, add_prefix: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Transform bus ID to model commodity format.\n",
    "    \n",
    "    Converts OpenStreetMap bus identifiers to VerveStacks model commodities\n",
    "    by cleaning prefixes and optionally adding model prefix.\n",
    "    \n",
    "    Args:\n",
    "        bus_id: Bus identifier (e.g., \"way/12345\", \"relation/67890\")\n",
    "        add_prefix: Whether to add \"e_\" prefix for model commodity format\n",
    "        \n",
    "    Returns:\n",
    "        Formatted commodity string\n",
    "        \n",
    "    Examples:\n",
    "        >>> bus_id_to_commodity(\"way/12345\")\n",
    "        'e_w12345'\n",
    "        >>> bus_id_to_commodity(\"relation/67890\", add_prefix=False)\n",
    "        'r67890'\n",
    "    \"\"\"\n",
    "    if not isinstance(bus_id, str):\n",
    "        raise ValueError(f\"Bus ID must be string, got {type(bus_id)}\")\n",
    "    \n",
    "    # Clean bus ID: way/ → w, relation/ → r\n",
    "    clean_id = bus_id.replace('way/', 'w').replace('relation/', 'r')\n",
    "    \n",
    "    # Add model prefix if requested\n",
    "    if add_prefix:\n",
    "        return f\"e_{clean_id}\"\n",
    "    return clean_id\n",
    "\n",
    "# THIS WILL BE CALLED WHEN GRID_MODEL IS ACTIVE\n",
    "# this function manages solar and wind generation at the grid cell level\n",
    "# it then aggregates the solar and wind generation to the bus level\n",
    "# it then creates the pre and post tables for the solar and wind generation\n",
    "# it then creates the pre and post tables for the aggregator\n",
    "# it then creates the pre and post tables for the aggregator\n",
    "\n",
    "input_iso = 'CHE'\n",
    "\n",
    "\n",
    "df_bus_load_share = pd.read_csv(f\"1_grids/output/{input_iso}/{input_iso}_bus_load_share.csv\")\n",
    "\n",
    "\n",
    "df_bus_load_share['bus_id'] = df_bus_load_share['bus_id'].apply(lambda x: bus_id_to_commodity(x, add_prefix=True))\n",
    "\n",
    "duckdb.register('df_bus_load_share', df_bus_load_share)\n",
    "\n",
    "df_elc_demand_shares = duckdb.sql(\"\"\"\n",
    "    select \n",
    "    'flo_shar' as attribute, \n",
    "    'elc_demand' as process, \n",
    "    bus_id as commodity, load_share * .99 as \"2022\",3 AS \"0\",'lo' as lim_type,\n",
    "    from df_bus_load_share\n",
    "\"\"\").to_df()\n",
    "\n",
    "# display(df_elc_demand_shares)\n",
    "\n",
    "\n",
    "df_elc_demand_topins = duckdb.sql(\"\"\"\n",
    "    select \n",
    "    'elc_demand' as process, \n",
    "    group_concat(bus_id) as commodity,\n",
    "    'in' AS \"io\",\n",
    "    from df_bus_load_share\n",
    "\"\"\").to_df()\n",
    "\n",
    "# display(df_elc_demand_topins)\n",
    "\n",
    "\n",
    "lines_df = pd.read_csv(f\"1_grids/output/{input_iso}/{input_iso}_clustered_lines.csv\")\n",
    "\n",
    "# Transform bus IDs to commodity format using standardized function\n",
    "lines_df['comm1'] = lines_df['bus0'].apply(lambda x: bus_id_to_commodity(x, add_prefix=False))\n",
    "lines_df['comm2'] = lines_df['bus1'].apply(lambda x: bus_id_to_commodity(x, add_prefix=False))\n",
    "\n",
    "# display(lines_df)\n",
    "\n",
    "duckdb.register('lines_df', lines_df)\n",
    "\n",
    "df_grids_parameters = duckdb.sql(\"\"\"\n",
    "with lines as (\n",
    "        SELECT comm1, comm2, type, bus0, bus1,\n",
    "               round(max(length)/1000, 0) as length_km,\n",
    "               sum(s_nom)/1000 as gw\n",
    "        FROM lines_df\n",
    "        GROUP BY comm1, comm2, type, bus0, bus1\n",
    "        )\n",
    "      select 'g_' || comm1 || '-' || comm2 AS process, gw AS pasti,\n",
    "        1.1 * length_km as ncap_cost,\n",
    "        0.00006 * length_km as efficiency\n",
    "        from lines\n",
    "        order by process\n",
    "    \"\"\").to_df()\n",
    "\n",
    "display(df_grids_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c24088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WILL BE CALLED WHEN GRID_MODEL IS NOT ACTIVE\n",
    "# this function manages solar and wind generation at the grid cell level\n",
    "# it then aggregates the solar and wind generation to the bus level\n",
    "# it then creates the pre and post tables for the solar and wind generation\n",
    "# it then creates the pre and post tables for the aggregator\n",
    "# it then creates the pre and post tables for the aggregator\n",
    "\n",
    "from this import d\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "\n",
    "input_iso = 'IND'\n",
    "\n",
    "\n",
    "# Simple read\n",
    "df_solar = pd.read_csv(\"data/REZoning/REZoning_Solar.csv\")\n",
    "df_solar = df_solar[df_solar['ISO'] == input_iso]\n",
    "\n",
    "df_wind = pd.read_csv(\"data/REZoning/REZoning_WindOnshore.csv\")\n",
    "df_wind = df_wind[df_wind['ISO'] == input_iso]\n",
    "\n",
    "df_costs = pd.read_csv(\"data/REZoning/REZoning_costs_per_kw.csv\")\n",
    "df_costs = df_costs[df_costs['iso'] == input_iso]\n",
    "\n",
    "\n",
    "# For each distinct grid_cell, retain the row with the maximum Installed Capacity Potential (MW)\n",
    "# If there are ties, also retain the maximum Capacity Factor for that grid_cell\n",
    "\n",
    "\n",
    "# For each distinct grid_cell, retain the row with the maximum Installed Capacity Potential (MW)\n",
    "# If there are ties, also retain the maximum Capacity Factor for that grid_cell\n",
    "\n",
    "# First, sort by 'Installed Capacity Potential (MW)' descending, then by 'Capacity Factor' descending\n",
    "df_wind = df_wind.sort_values(['grid_cell', 'Installed Capacity Potential (MW)', 'Capacity Factor'], ascending=[True, False, False])\n",
    "# Drop duplicates, keeping the row with the highest Installed Cap (and highest Capacity Factor in case of ties)\n",
    "df_wind = df_wind.drop_duplicates(subset=['grid_cell'], keep='first')\n",
    "\n",
    "\n",
    "duckdb.register('df_wind', df_wind)\n",
    "\n",
    "df_won_fi_t = duckdb.sql(f\"\"\"\n",
    "    WITH wind_with_lcoe_class AS (\n",
    "        SELECT\n",
    "            *,\"LCOE (USD/MWh)\" - (T2.invcost*.1102 + T2.fixom)/8.76/\"capacity factor\" - 4 AS non_gen_lcoe,\n",
    "            NTILE(5) OVER (\n",
    "                PARTITION BY round(\"Capacity Factor\", 2)\n",
    "                ORDER BY \"LCOE (USD/MWh)\" - (T2.invcost*.1102 + T2.fixom)/8.76/\"capacity factor\" - 4\n",
    "            ) AS lcoe_class\n",
    "        FROM df_wind T1\n",
    "        inner join df_costs T2\n",
    "        on T2.tech = 'windons'\n",
    "    )\n",
    "    SELECT\n",
    "        'e_won-' || ISO || '_' || cast(round(\"capacity factor\",2)*100 as int) || '_c' || lcoe_class AS \"process\",\n",
    "        'elc_won-' || ISO AS \"comm-out\",\n",
    "        SUM(\"Installed Capacity Potential (MW)\")/1000 AS \"cap_bnd\",\n",
    "        SUM(\"Capacity Factor\" * \"Installed Capacity Potential (MW)\")/SUM(\"Installed Capacity Potential (MW)\") AS \"af~fx\",\n",
    "        SUM(non_gen_lcoe * \"Installed Capacity Potential (MW)\")/SUM(\"Installed Capacity Potential (MW)\") / .1102 AS \"ncap_cost~USD21_alt\",\n",
    "        lcoe_class\n",
    "    FROM wind_with_lcoe_class\n",
    "    GROUP BY ISO, round(\"capacity factor\",2), lcoe_class\n",
    "    order by \"af~fx\" desc\n",
    "\n",
    "\"\"\").to_df()\n",
    "\n",
    "\n",
    "duckdb.register('df_won_fi_t', df_won_fi_t)\n",
    "\n",
    "df_won_fi_p = duckdb.sql(\"\"\"\n",
    "select \n",
    "'ele' AS set,\n",
    "process, \n",
    "'wind resource -- CF class ' || substr(process, instr(process, '_')+1, instr(process, '_c')-instr(process, '_')-1) || \n",
    "' -- cost class ' || substr(process, instr(process, '_c')+2) AS description,\n",
    "'GW' AS capacity_unit,\n",
    "'TWh' AS activity_unit,\n",
    "'annual' AS timeslicelevel,\n",
    "'no' AS vintage\n",
    "from df_wind_fi_t T1\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_won_fi_p)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# First, sort by 'Calculated Installed Cap' descending, then by 'Capacity Factor' descending\n",
    "df_solar = df_solar.sort_values(['grid_cell', 'Installed Capacity Potential (MW)', 'Capacity Factor'], ascending=[True, False, False])\n",
    "# Drop duplicates, keeping the row with the highest Installed Cap (and highest Capacity Factor in case of ties)\n",
    "df_solar = df_solar.drop_duplicates(subset=['grid_cell'], keep='first')\n",
    "\n",
    "\n",
    "duckdb.register('df_solar', df_solar)\n",
    "\n",
    "df_solar_fi_t = duckdb.sql(f\"\"\"\n",
    "    WITH solar_with_lcoe_class AS (\n",
    "        SELECT\n",
    "            *,\"LCOE (USD/MWh)\" - (T2.invcost*.1102 + T2.fixom)/8.76/\"capacity factor\" - 4 AS non_gen_lcoe,\n",
    "            NTILE(5) OVER (\n",
    "                PARTITION BY round(\"Capacity Factor\", 2)\n",
    "                ORDER BY \"LCOE (USD/MWh)\" - (T2.invcost*.1102 + T2.fixom)/8.76/\"capacity factor\" - 4\n",
    "            ) AS lcoe_class\n",
    "        FROM df_solar T1\n",
    "        inner join df_costs T2\n",
    "        on T1.ISO = T2.iso AND T2.tech = 'solarpv'\n",
    "    )\n",
    "    SELECT\n",
    "        'e_spv-' || ISO || '_' || cast(round(\"capacity factor\",2)*100 as int) || '_c' || lcoe_class AS \"process\",\n",
    "        'elc_spv-' || ISO AS \"comm-out\",\n",
    "        SUM(\"Installed Capacity Potential (MW)\")/1000 AS \"cap_bnd\",\n",
    "        SUM(\"Capacity Factor\" * \"Installed Capacity Potential (MW)\")/SUM(\"Installed Capacity Potential (MW)\") AS \"af~fx\",\n",
    "        SUM(non_gen_lcoe * \"Installed Capacity Potential (MW)\")/SUM(\"Installed Capacity Potential (MW)\") / .1102 AS \"ncap_cost~USD21_alt\",\n",
    "        lcoe_class\n",
    "    FROM solar_with_lcoe_class\n",
    "    GROUP BY ISO, round(\"capacity factor\",2), lcoe_class\n",
    "    order by \"af~fx\" desc\n",
    "\n",
    "\"\"\").to_df()\n",
    "\n",
    "\n",
    "duckdb.register('df_solar_fi_t', df_solar_fi_t)\n",
    "\n",
    "df_solar_fi_p = duckdb.sql(\"\"\"\n",
    "select \n",
    "'ele' AS set,\n",
    "process, \n",
    "'solar resource -- CF class ' || substr(process, instr(process, '_')+1, instr(process, '_c')-instr(process, '_')-1) || \n",
    "' -- cost class ' || substr(process, instr(process, '_c')+2) AS description,\n",
    "'GW' AS capacity_unit,\n",
    "'TWh' AS activity_unit,\n",
    "'annual' AS timeslicelevel,\n",
    "'no' AS vintage\n",
    "from df_solar_fi_t T1\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_solar_fi_p)\n",
    "\n",
    "\n",
    "df_fi_comm_sol_win = duckdb.sql(\"\"\"\n",
    "    select 'NRG' AS \"set\",\"comm-out\" as commodity, 'solar generation'  as \"description\"\n",
    "        ,'ELC' as commoditytype, 'daynite' as \"timeslicelevel\", 'TWh' as unit\n",
    "        from df_solar_fi_t\n",
    "        UNION\n",
    "        select 'NRG' AS \"set\",\"comm-out\" as commodity, 'wind generation' as \"description\"\n",
    "        ,'ELC' as commoditytype, 'daynite' as \"timeslicelevel\", 'TWh' as unit\n",
    "        from df_won_fi_t\n",
    "        order by \"comm-out\"\n",
    "\"\"\").to_df()\n",
    "\n",
    "display(df_fi_comm_sol_win)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b32a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "\n",
    "input_iso = 'CHE'\n",
    "\n",
    "\n",
    "# Simple read - this should come from the cache\n",
    "df_solar_rezoning = pd.read_csv(\"data/REZoning/REZoning_Solar.csv\")\n",
    "\n",
    "df_solar = df_solar_rezoning[df_solar_rezoning['ISO'] == input_iso]\n",
    "\n",
    "\n",
    "df_solar = df_solar.drop_duplicates(subset='grid_cell', keep='first')\n",
    "\n",
    "# display(df_solar)\n",
    "\n",
    "# Shortlist records that capture 95% of installed capacity potential\n",
    "\n",
    "# Sort by installed capacity descending\n",
    "df_solar_sorted = df_solar.sort_values(by='Installed Capacity Potential (MW)', ascending=False)\n",
    "\n",
    "# Calculate cumulative sum and total\n",
    "df_solar_sorted['cumulative_cap'] = df_solar_sorted['Installed Capacity Potential (MW)'].cumsum()\n",
    "total_cap = df_solar_sorted['Installed Capacity Potential (MW)'].sum()\n",
    "\n",
    "# Find cutoff for 95% of total capacity\n",
    "df_solar_sorted['cumulative_pct'] = df_solar_sorted['cumulative_cap'] / total_cap\n",
    "\n",
    "# Select rows up to 95% of total capacity\n",
    "df_solar_95 = df_solar_sorted[df_solar_sorted['cumulative_pct'] <= 0.97]\n",
    "\n",
    "# If the last included row doesn't reach exactly 95%, include the next row to ensure at least 95%\n",
    "if not df_solar_95.empty and df_solar_95['cumulative_pct'].iloc[-1] < 0.97:\n",
    "    next_idx = df_solar_95.index[-1] + 1\n",
    "    if next_idx in df_solar_sorted.index:\n",
    "        df_solar_95 = df_solar_sorted.loc[:next_idx]\n",
    "\n",
    "# display(df_solar_95)\n",
    "\n",
    "df_wind = pd.read_csv(\"data/REZoning/REZoning_WindOnshore.csv\")\n",
    "\n",
    "df_wind = df_wind[df_wind['ISO'] == input_iso]\n",
    "\n",
    "df_wind = df_wind.drop_duplicates(subset='grid_cell', keep='first')\n",
    "\n",
    "df_wind_sorted = df_wind.sort_values(by='Installed Capacity Potential (MW)', ascending=False)\n",
    "\n",
    "df_wind_sorted['cumulative_cap'] = df_wind_sorted['Installed Capacity Potential (MW)'].cumsum()\n",
    "total_cap = df_wind_sorted['Installed Capacity Potential (MW)'].sum()\n",
    "\n",
    "df_wind_sorted['cumulative_pct'] = df_wind_sorted['cumulative_cap'] / total_cap\n",
    "\n",
    "df_wind_95 = df_wind_sorted[df_wind_sorted['cumulative_pct'] <= 0.97]\n",
    "\n",
    "if not df_wind_95.empty and df_wind_95['cumulative_pct'].iloc[-1] < 0.97:\n",
    "    next_idx = df_wind_95.index[-1] + 1\n",
    "    if next_idx in df_wind_sorted.index:\n",
    "        df_wind_95 = df_wind_sorted.loc[:next_idx]\n",
    "\n",
    "# display(df_wind_95)\n",
    "\n",
    "# Identify wind records with LCOE more than 2 standard deviations above the mean\n",
    "lcoe_mean = df_wind['LCOE (USD/MWh)'].mean()\n",
    "lcoe_std = df_wind['LCOE (USD/MWh)'].std()\n",
    "high_lcoe_threshold = lcoe_mean + 1 * lcoe_std\n",
    "\n",
    "df_wind_high_lcoe = df_wind[df_wind['LCOE (USD/MWh)'] > high_lcoe_threshold]\n",
    "\n",
    "display(df_wind_high_lcoe)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e532580",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "input_iso = 'CHE'\n",
    "\n",
    "\n",
    "# Load REF_NTC data for function development\n",
    "def load_ref_ntc_data():\n",
    "    \"\"\"Load and process REF_NTC interconnector data\"\"\"\n",
    "    file_path = \"data/ember/europe_interconnection_data/Interconnectors/REF_NTC.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "df_ntc = load_ref_ntc_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shared_data_loader import get_shared_loader\n",
    "import duckdb\n",
    "\n",
    "input_iso = 'CHE'\n",
    "\n",
    "\n",
    "df_bus_load_share = pd.read_csv(f\"1_grids/output/{input_iso}/{input_iso}_bus_load_share_voronoi.csv\")\n",
    "df_bus_load_share = df_bus_load_share[df_bus_load_share['load_share'] > 0].copy()\n",
    "df_bus_load_share['bus_id'] = df_bus_load_share['bus_id'].apply(lambda x: bus_id_to_commodity(x, add_prefix=False))\n",
    "\n",
    "\n",
    "shared_loader = get_shared_loader(\"data/\")\n",
    "df_dem_techs = shared_loader.get_vs_mappings_sheet('dem_techs')\n",
    "\n",
    "duckdb.register('df_bus_load_share', df_bus_load_share)\n",
    "duckdb.register('df_dem_techs', df_dem_techs)\n",
    "\n",
    "\n",
    "df_demtech_topins = duckdb.sql(\"\"\"\n",
    "    select \n",
    "    T2.tech || '_'|| T1.bus_id as process,\n",
    "    'e_' || T1.bus_id as commodity,\n",
    "    'IN' as \"io\",\n",
    "    from df_bus_load_share T1\n",
    "    cross join df_dem_techs T2\n",
    "    \"\"\").to_df()\n",
    "\n",
    "\n",
    "\n",
    "df_demtech_flo_mark = duckdb.sql(\"\"\"\n",
    "    select \n",
    "    T2.tech || '_'|| T1.bus_id as process,\n",
    "    'elc_buildings,elc_transport,elc_industry,elc_roadtransport' as commodity,\n",
    "    T1.load_share as \"flo_mark\",\n",
    "    'lo' as lim_type,\n",
    "    from df_bus_load_share T1\n",
    "    cross join df_dem_techs T2\n",
    "    \"\"\").to_df()\n",
    "\n",
    "display(df_demtech_flo_mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c170a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spatial_utils import bus_id_to_commodity\n",
    "\n",
    "input_iso = 'CHE'\n",
    "\n",
    "\n",
    "buses_df = pd.read_csv(f\"1_grids/output/{input_iso}/{input_iso}_clustered_buses.csv\")\n",
    "\n",
    "# Find tags with more than one row\n",
    "tag_counts = buses_df['tags'].value_counts()\n",
    "multi_tag = tag_counts[tag_counts > 1].index\n",
    "# Filter to only those tags\n",
    "df_multi = buses_df[buses_df['tags'].isin(multi_tag)].copy()\n",
    "\n",
    "# Sort by tag and voltage descending (convert voltage to numeric for sorting)\n",
    "df_multi['voltage_num'] = pd.to_numeric(df_multi['voltage'], errors='coerce')\n",
    "df_multi = df_multi.sort_values(['tags', 'voltage_num'], ascending=[True, False])\n",
    "\n",
    "# For each tag, create step-down transformer records\n",
    "stepdown_records = []\n",
    "for tag, group in df_multi.groupby('tags'):\n",
    "    group_sorted = group.sort_values('voltage_num', ascending=False)\n",
    "    bus_ids = group_sorted['bus_id'].tolist()\n",
    "    voltages = group_sorted['voltage_num'].tolist()\n",
    "    for i in range(len(bus_ids) - 1):\n",
    "        higher_bus = bus_ids[i]\n",
    "        lower_bus = bus_ids[i+1]\n",
    "        higher_v = voltages[i]\n",
    "        lower_v = voltages[i+1]\n",
    "        # Pass bus ids through bus_id_to_commodity\n",
    "        comm_in = bus_id_to_commodity(higher_bus, add_prefix=True)\n",
    "        comm_out = bus_id_to_commodity(lower_bus, add_prefix=True)\n",
    "        stepdown_records.append({\n",
    "            'process': f\"stepdown_{bus_id_to_commodity(tag, add_prefix=False)}_{int(higher_v)}to{int(lower_v)}\",\n",
    "            'comm-in': comm_in,\n",
    "            'comm-out': comm_out,\n",
    "            'efficiency': 1\n",
    "        })\n",
    "\n",
    "df_stepdown = pd.DataFrame(stepdown_records)\n",
    "display(df_stepdown)\n",
    "\n",
    "\n",
    "# Create a table with process, description, act unit, cap unit, timeslicelevel\n",
    "df_stepdown_desc = pd.DataFrame({\n",
    "    'set': \"pre\",\n",
    "    'process': df_stepdown['process'],\n",
    "    'description': (\n",
    "        \"Step-down transformer: \"\n",
    "        + df_stepdown['comm-in'] + \" → \" + df_stepdown['comm-out']\n",
    "    ),\n",
    "    'activityunit': \"TWh\",\n",
    "    'capacityunit': \"GW\",\n",
    "    'timeslicelevel': \"daynite\"\n",
    "})\n",
    "display(df_stepdown_desc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a64336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spatial_utils import bus_id_to_commodity\n",
    "\n",
    "input_iso = 'CHE'\n",
    "\n",
    "\n",
    "# Load REZoning data directly (not yet in shared_data_loader)\n",
    "df_solar_rezoning = pd.read_csv(\"data/REZoning/REZoning_Solar.csv\")\n",
    "df_wind_rezoning = pd.read_csv(\"data/REZoning/REZoning_WindOnshore.csv\")\n",
    "\n",
    "# Load clustered buses data\n",
    "buses_df = pd.read_csv(f\"1_grids/output/{input_iso}/{input_iso}_clustered_buses.csv\")\n",
    "\n",
    "# Function to strip voltage from bus_id\n",
    "def strip_voltage_from_bus_id(bus_id):\n",
    "    \"\"\"Remove voltage suffix from bus_id (e.g., 'bus123-380' -> 'bus123')\"\"\"\n",
    "    if isinstance(bus_id, str) and '-' in bus_id:\n",
    "        # Split by '-' and take all parts except the last one if it's numeric (voltage)\n",
    "        parts = bus_id.split('-')\n",
    "        if len(parts) > 1 and parts[-1].isdigit():\n",
    "            return '-'.join(parts[:-1])\n",
    "    return bus_id\n",
    "\n",
    "# Apply voltage stripping to bus_id column\n",
    "buses_df['clean_bus_id'] = buses_df['bus_id'].apply(strip_voltage_from_bus_id)\n",
    "\n",
    "# Get distinct clean_bus_id with coordinates (keep first occurrence for each clean_bus_id)\n",
    "buses_distinct = buses_df.drop_duplicates(subset=['clean_bus_id'], keep='first')\n",
    "\n",
    "# Create a table with set = p_busid_to_commodity(bus_id), pset_co = p_busid_to_commodity(bus_id, True)\n",
    "# write this df on a new sheet called \"geolocation\" in syssettings. veda marker (~geolocation)\n",
    "\n",
    "# Create geolocation DataFrame from buses\n",
    "df_geolocation_buses = pd.DataFrame({\n",
    "    'grid_node': buses_distinct['clean_bus_id'].apply(lambda x: f\"p_{bus_id_to_commodity(x, add_prefix=False)}\"),\n",
    "    'lat': buses_distinct['x'],\n",
    "    'lng': buses_distinct['y']\n",
    "})\n",
    "\n",
    "# Add REZoning solar grid cells to geolocation\n",
    "df_solar_iso = df_solar_rezoning[df_solar_rezoning['ISO'] == input_iso]\n",
    "df_geolocation_solar = pd.DataFrame({\n",
    "    'grid_node': df_solar_iso['grid_cell'].apply(lambda x: f\"rez_{x}\"),\n",
    "    'lat': df_solar_iso['lat'],\n",
    "    'lng': df_solar_iso['long']\n",
    "})\n",
    "\n",
    "# Combine both geolocation sources\n",
    "df_geolocation = pd.concat([df_geolocation_buses, df_geolocation_solar], ignore_index=True)\n",
    "\n",
    "# Remove duplicates based on grid_node (keep first occurrence)\n",
    "df_geolocation = df_geolocation.drop_duplicates(subset=['grid_node'], keep='first')\n",
    "\n",
    "\n",
    "display(df_geolocation)\n",
    "\n",
    "# write this df on a new sheet called \"geo_sets\" in Sets-vervestacks (veda marker (~tfm_pset))\n",
    "df_set_psetco = pd.DataFrame({\n",
    "    'setname': buses_distinct['clean_bus_id'].apply(lambda x: f\"p_{bus_id_to_commodity(x, add_prefix=False)}\"),\n",
    "    'pset_co': buses_distinct['clean_bus_id'].apply(lambda x: f\"{bus_id_to_commodity(x, add_prefix=True)}*\")\n",
    "})\n",
    "\n",
    "\n",
    "df_solar_set_psetco = pd.DataFrame({\n",
    "    'setname': df_solar_iso['grid_cell'].apply(lambda x: f\"rez_{x}\"),\n",
    "    'pset_co': df_solar_iso.apply(lambda row: f\"elc*{row['ISO']}_{str(row['id']).zfill(4)}\", axis=1)\n",
    "})\n",
    "\n",
    "df_set_psetco = pd.concat([df_set_psetco, df_solar_set_psetco], ignore_index=True)\n",
    "    \n",
    "display(df_set_psetco)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
